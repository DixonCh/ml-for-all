{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple neural network Multi-layer perceptron\n",
    "\n",
    "A feed-forward bachpropagation multilayer perceptron neural network using TensorFlow to classify Nepali handwritten digits.\n",
    "\n",
    "- Author: Ashok Kuamr Pant\n",
    "- Company: Treeleaf Technologies Pvt. Ltd. (treeleaf.ai)\n",
    "- Email: asokpant@gmail.com\n",
    "- Date: 11 May, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Nepali Handwritten Character Dataset Overview\n",
    "### Overview\n",
    "NHCD dataset is a Nepali handwritten character dataset. It contains three individual categories (numerals, vowels and consonants). Samples are collected from 40 individuals from different fields and cropped for character boundary and resized to 28x28.\n",
    "\n",
    "* Numerals (288 samples per class, 10 classes)\n",
    "* Vowels (221 samples per class, 12 classes)\n",
    "* Consonants (205 samples per class, 36 classes)\n",
    "\n",
    "### Samples\n",
    "* Numerals ![numerals.png](../../data/numerals.png)\n",
    "* Vowels ![vowels.png](../../data/vowels.png)\n",
    "* Consonants ![consonants.png](../../data/consonants.png)\n",
    "    \n",
    "### Citation\n",
    "Please cite in your publications if it helps your research:\n",
    "\n",
    "    ```text\n",
    "    @inproceedings{pant2012off,\n",
    "      title={Off-line Nepali handwritten character recognition using Multilayer Perceptron and Radial Basis Function neural networks},\n",
    "      author={Pant, Ashok Kumar and Panday, Sanjeeb Prasad and Joshi, Shashidhar Ram},\n",
    "      booktitle={2012 Third Asian Himalayas International Conference on Internet},\n",
    "      pages={1--5},\n",
    "      year={2012},\n",
    "      organization={IEEE}\n",
    "    }\n",
    "    ```\n",
    "\n",
    "More info: https://www.kaggle.com/ashokpant/devanagari-character-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashok/anaconda3/envs/ml3/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "tf.set_random_seed(1234)\n",
    "np.random.seed(1234)\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: 10, Label map: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9'}\n",
      "Train samples: 2304, Test samples: 576\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "from utils.dataset import create_handwritten_dataset\n",
    "\n",
    "train_data, train_labels, test_data, test_labels, label_map = create_handwritten_dataset(\n",
    "        \"/home/ashok/Data/Datasets/devanagari-character-dataset/nhcd/numerals\", test_ratio=0.2)\n",
    "\n",
    "n_classes = len(label_map)\n",
    "image_size = (28, 28)\n",
    "image_channel = 1\n",
    "n_train_samples = len(train_labels)\n",
    "n_test_samples = len(test_labels)\n",
    "\n",
    "print(\"Classes: {}, Label map: {}\".format(n_classes, label_map))\n",
    "print(\"Train samples: {}, Test samples: {}\".format(n_train_samples, n_test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 200\n",
    "batch_size = 128\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-d5c231120594>:43: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 784 # NHCD data input (img shape: 28*28)\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_input], name=\"x\")\n",
    "y = tf.placeholder(\"float\", [None, n_classes], name=\"y\")\n",
    "\n",
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "   \n",
    "    return out_layer\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# Predictions\n",
    "pred_probas = tf.nn.softmax(pred)\n",
    "pred_classes = tf.argmax(pred, axis=1)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "acc =  tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001, cost = 5726.769500732\n",
      "Epoch: 0002, cost = 374.416338603\n",
      "Epoch: 0003, cost = 245.919551426\n",
      "Epoch: 0004, cost = 181.263372633\n",
      "Epoch: 0005, cost = 143.947429657\n",
      "Epoch: 0006, cost = 117.932838016\n",
      "Epoch: 0007, cost = 101.671468523\n",
      "Epoch: 0008, cost = 86.977004157\n",
      "Epoch: 0009, cost = 75.855136236\n",
      "Epoch: 0010, cost = 66.139711168\n",
      "Epoch: 0011, cost = 59.041572995\n",
      "Epoch: 0012, cost = 51.464596007\n",
      "Epoch: 0013, cost = 46.366860602\n",
      "Epoch: 0014, cost = 42.775164816\n",
      "Epoch: 0015, cost = 38.312017441\n",
      "Epoch: 0016, cost = 35.144023418\n",
      "Epoch: 0017, cost = 31.373642604\n",
      "Epoch: 0018, cost = 28.494442569\n",
      "Epoch: 0019, cost = 26.668315199\n",
      "Epoch: 0020, cost = 25.347460535\n",
      "Epoch: 0021, cost = 22.973378075\n",
      "Epoch: 0022, cost = 20.334816668\n",
      "Epoch: 0023, cost = 19.203133901\n",
      "Epoch: 0024, cost = 17.972181002\n",
      "Epoch: 0025, cost = 16.085227278\n",
      "Epoch: 0026, cost = 14.742126491\n",
      "Epoch: 0027, cost = 13.505850606\n",
      "Epoch: 0028, cost = 12.940384971\n",
      "Epoch: 0029, cost = 12.361823559\n",
      "Epoch: 0030, cost = 11.142517355\n",
      "Epoch: 0031, cost = 10.307744384\n",
      "Epoch: 0032, cost = 10.270739900\n",
      "Epoch: 0033, cost = 9.129735496\n",
      "Epoch: 0034, cost = 9.063644105\n",
      "Epoch: 0035, cost = 8.027213620\n",
      "Epoch: 0036, cost = 7.826961663\n",
      "Epoch: 0037, cost = 7.485765696\n",
      "Epoch: 0038, cost = 6.688185679\n",
      "Epoch: 0039, cost = 6.099423455\n",
      "Epoch: 0040, cost = 5.411392980\n",
      "Epoch: 0041, cost = 5.615282979\n",
      "Epoch: 0042, cost = 5.286262231\n",
      "Epoch: 0043, cost = 4.629059530\n",
      "Epoch: 0044, cost = 4.680813248\n",
      "Epoch: 0045, cost = 4.404811509\n",
      "Epoch: 0046, cost = 4.250656166\n",
      "Epoch: 0047, cost = 3.544625704\n",
      "Epoch: 0048, cost = 3.343877068\n",
      "Epoch: 0049, cost = 3.301316013\n",
      "Epoch: 0050, cost = 3.236558790\n",
      "Epoch: 0051, cost = 3.005392833\n",
      "Epoch: 0052, cost = 2.885359643\n",
      "Epoch: 0053, cost = 2.542073894\n",
      "Epoch: 0054, cost = 2.355689644\n",
      "Epoch: 0055, cost = 2.532505097\n",
      "Epoch: 0056, cost = 2.098918961\n",
      "Epoch: 0057, cost = 2.112729650\n",
      "Epoch: 0058, cost = 1.911579486\n",
      "Epoch: 0059, cost = 1.875442396\n",
      "Epoch: 0060, cost = 1.787720595\n",
      "Epoch: 0061, cost = 1.583936096\n",
      "Epoch: 0062, cost = 1.478964302\n",
      "Epoch: 0063, cost = 1.313867286\n",
      "Epoch: 0064, cost = 1.636156192\n",
      "Epoch: 0065, cost = 1.278399634\n",
      "Epoch: 0066, cost = 1.265461438\n",
      "Epoch: 0067, cost = 1.272304916\n",
      "Epoch: 0068, cost = 0.916275765\n",
      "Epoch: 0069, cost = 0.943034063\n",
      "Epoch: 0070, cost = 0.735176374\n",
      "Epoch: 0071, cost = 0.776762940\n",
      "Epoch: 0072, cost = 0.664921496\n",
      "Epoch: 0073, cost = 0.560965381\n",
      "Epoch: 0074, cost = 0.507131785\n",
      "Epoch: 0075, cost = 0.540435826\n",
      "Epoch: 0076, cost = 0.480896343\n",
      "Epoch: 0077, cost = 0.593119558\n",
      "Epoch: 0078, cost = 0.432937741\n",
      "Epoch: 0079, cost = 0.326219156\n",
      "Epoch: 0080, cost = 0.393852058\n",
      "Epoch: 0081, cost = 0.414856530\n",
      "Epoch: 0082, cost = 0.345936584\n",
      "Epoch: 0083, cost = 0.328818857\n",
      "Epoch: 0084, cost = 0.338562914\n",
      "Epoch: 0085, cost = 0.268391035\n",
      "Epoch: 0086, cost = 0.246321256\n",
      "Epoch: 0087, cost = 0.260551523\n",
      "Epoch: 0088, cost = 0.225257049\n",
      "Epoch: 0089, cost = 0.304842110\n",
      "Epoch: 0090, cost = 0.203683539\n",
      "Epoch: 0091, cost = 0.219796171\n",
      "Epoch: 0092, cost = 0.198369629\n",
      "Epoch: 0093, cost = 0.126912091\n",
      "Epoch: 0094, cost = 0.142991215\n",
      "Epoch: 0095, cost = 0.213465002\n",
      "Epoch: 0096, cost = 0.106099014\n",
      "Epoch: 0097, cost = 0.138902774\n",
      "Epoch: 0098, cost = 0.104623001\n",
      "Epoch: 0099, cost = 0.063796815\n",
      "Epoch: 0100, cost = 0.091547828\n",
      "Epoch: 0101, cost = 0.082602769\n",
      "Epoch: 0102, cost = 0.058823039\n",
      "Epoch: 0103, cost = 0.096667927\n",
      "Epoch: 0104, cost = 0.176491726\n",
      "Epoch: 0105, cost = 0.092235278\n",
      "Epoch: 0106, cost = 0.089782115\n",
      "Epoch: 0107, cost = 0.044142835\n",
      "Epoch: 0108, cost = 0.068553666\n",
      "Epoch: 0109, cost = 0.030414305\n",
      "Epoch: 0110, cost = 0.022162634\n",
      "Epoch: 0111, cost = 0.048624659\n",
      "Epoch: 0112, cost = 0.033717487\n",
      "Epoch: 0113, cost = 0.025636653\n",
      "Epoch: 0114, cost = 0.018508667\n",
      "Epoch: 0115, cost = 0.016867873\n",
      "Epoch: 0116, cost = 0.003608303\n",
      "Epoch: 0117, cost = 0.052823296\n",
      "Epoch: 0118, cost = 0.021956619\n",
      "Epoch: 0119, cost = 0.000032964\n",
      "Epoch: 0120, cost = 0.000007222\n",
      "Epoch: 0121, cost = 0.000005587\n",
      "Epoch: 0122, cost = 0.000004673\n",
      "Epoch: 0123, cost = 0.000004079\n",
      "Epoch: 0124, cost = 0.000003657\n",
      "Epoch: 0125, cost = 0.000003340\n",
      "Epoch: 0126, cost = 0.000003090\n",
      "Epoch: 0127, cost = 0.000002886\n",
      "Epoch: 0128, cost = 0.000002716\n",
      "Epoch: 0129, cost = 0.000002572\n",
      "Epoch: 0130, cost = 0.000002447\n",
      "Epoch: 0131, cost = 0.000002338\n",
      "Epoch: 0132, cost = 0.000002242\n",
      "Epoch: 0133, cost = 0.000002154\n",
      "Epoch: 0134, cost = 0.000002075\n",
      "Epoch: 0135, cost = 0.000002004\n",
      "Epoch: 0136, cost = 0.000001939\n",
      "Epoch: 0137, cost = 0.000001878\n",
      "Epoch: 0138, cost = 0.000001821\n",
      "Epoch: 0139, cost = 0.000001769\n",
      "Epoch: 0140, cost = 0.000001720\n",
      "Epoch: 0141, cost = 0.000001675\n",
      "Epoch: 0142, cost = 0.000001633\n",
      "Epoch: 0143, cost = 0.000001592\n",
      "Epoch: 0144, cost = 0.000001555\n",
      "Epoch: 0145, cost = 0.000001519\n",
      "Epoch: 0146, cost = 0.000001485\n",
      "Epoch: 0147, cost = 0.000001453\n",
      "Epoch: 0148, cost = 0.000001423\n",
      "Epoch: 0149, cost = 0.000001394\n",
      "Epoch: 0150, cost = 0.000001367\n",
      "Epoch: 0151, cost = 0.000001341\n",
      "Epoch: 0152, cost = 0.000001316\n",
      "Epoch: 0153, cost = 0.000001293\n",
      "Epoch: 0154, cost = 0.000001270\n",
      "Epoch: 0155, cost = 0.000001248\n",
      "Epoch: 0156, cost = 0.000001228\n",
      "Epoch: 0157, cost = 0.000001207\n",
      "Epoch: 0158, cost = 0.000001188\n",
      "Epoch: 0159, cost = 0.000001169\n",
      "Epoch: 0160, cost = 0.000001152\n",
      "Epoch: 0161, cost = 0.000001135\n",
      "Epoch: 0162, cost = 0.000001118\n",
      "Epoch: 0163, cost = 0.000001103\n",
      "Epoch: 0164, cost = 0.000001087\n",
      "Epoch: 0165, cost = 0.000001072\n",
      "Epoch: 0166, cost = 0.000001058\n",
      "Epoch: 0167, cost = 0.000001045\n",
      "Epoch: 0168, cost = 0.000001031\n",
      "Epoch: 0169, cost = 0.000001018\n",
      "Epoch: 0170, cost = 0.000001005\n",
      "Epoch: 0171, cost = 0.000000993\n",
      "Epoch: 0172, cost = 0.000000981\n",
      "Epoch: 0173, cost = 0.000000970\n",
      "Epoch: 0174, cost = 0.000000958\n",
      "Epoch: 0175, cost = 0.000000947\n",
      "Epoch: 0176, cost = 0.000000937\n",
      "Epoch: 0177, cost = 0.000000926\n",
      "Epoch: 0178, cost = 0.000000916\n",
      "Epoch: 0179, cost = 0.000000906\n",
      "Epoch: 0180, cost = 0.000000897\n",
      "Epoch: 0181, cost = 0.000000887\n",
      "Epoch: 0182, cost = 0.000000878\n",
      "Epoch: 0183, cost = 0.000000870\n",
      "Epoch: 0184, cost = 0.000000861\n",
      "Epoch: 0185, cost = 0.000000852\n",
      "Epoch: 0186, cost = 0.000000844\n",
      "Epoch: 0187, cost = 0.000000836\n",
      "Epoch: 0188, cost = 0.000000828\n",
      "Epoch: 0189, cost = 0.000000820\n",
      "Epoch: 0190, cost = 0.000000813\n",
      "Epoch: 0191, cost = 0.000000806\n",
      "Epoch: 0192, cost = 0.000000798\n",
      "Epoch: 0193, cost = 0.000000791\n",
      "Epoch: 0194, cost = 0.000000784\n",
      "Epoch: 0195, cost = 0.000000778\n",
      "Epoch: 0196, cost = 0.000000771\n",
      "Epoch: 0197, cost = 0.000000765\n",
      "Epoch: 0198, cost = 0.000000759\n",
      "Epoch: 0199, cost = 0.000000752\n",
      "Epoch: 0200, cost = 0.000000746\n",
      "Optimization Finished!\n",
      "Train Accuracy: 100.00%\n",
      "Test Accuracy: 77.08%\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "\n",
    "config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(n_train_samples/batch_size)\n",
    "    if n_train_samples % batch_size != 0: # samller last batch\n",
    "        total_batch += 1\n",
    "\n",
    "    # Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        start = i*batch_size\n",
    "        end = start+batch_size\n",
    "        if end > n_train_samples:\n",
    "            end = n_train_samples-1\n",
    "        batch_x = train_data[start:end]\n",
    "        batch_y = train_labels[start:end]\n",
    "        # Run optimization op (backprop) and cost op (to get loss value)\n",
    "        _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
    "                                                      y: batch_y})\n",
    "        # Compute average loss\n",
    "        avg_cost += c / total_batch\n",
    "    # Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print(\"Epoch: {:04d}, cost = {:.9f}\".format(epoch+1, avg_cost))\n",
    "        \n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "# Testing\n",
    "train_acc = sess.run(acc, feed_dict={x:train_data, y: train_labels})\n",
    "test_acc = sess.run(acc, feed_dict={x:test_data, y: test_labels})\n",
    "\n",
    "print(\"Train Accuracy: {:.2f}%\".format(train_acc*100))\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAH8NJREFUeJztnWuIXdd5ht/Psh3Ld8mSJyOP7LGJSDGhscvgOCQExY6D\nm4b4n0kgxS0G/UmLQ1Niu4VCCgWXQkh/lIJo0hiSJjW51CaEBEW1KYXgeFzfZDuyZHl0y4xGki1Z\ncXzP1x9na/tdn2av2TNzrrPeB4az9tn77LPOPmfN/t71XZa5O4QQ5XHWoDsghBgMGvxCFIoGvxCF\nosEvRKFo8AtRKBr8QhSKBr8QhbKiwW9mt5rZbjPba2b3dKtTQojeY8sN8jGzNQBeAHALgEMAHgPw\nBXd/rnvdE0L0irNX8NobAOx1930AYGbfB3AbgMbBv2HDBp+cnFzBWwohcszMzODYsWPW5tiVDP4r\nAByk7UMAPpJ7weTkJKanp1fwlkKIHFNTU62P7fmEn5ltM7NpM5s+evRor99OCNGSlQz+wwA20/ZE\n9VyCu2939yl3n9q4ceMK3k4I0U1WMvgfA7DFzK42s3MBfB7AQ93plhCi1yxb87v7O2b2FwB+DmAN\ngG+5+7Nd65kQoqesZMIP7v5TAD/tUl+EEH1EEX5CFIoGvxCFosEvRKGsSPOLxcmFT//+979vdY6z\nzmr+H23WKphLiDPQnV+IQtHgF6JQNPiFKBRp/i4QdT1r+XfffTfZx9txX9P8wNlnp1/TmjVrFmwD\n6fyA5gNEDt35hSgUDX4hCkVm/zJhE/3tt99O9r311lt1+4033mjc9+abb7Z6r3POOSfZft/73le3\nzzvvvMZ9/LpRlwB8vaM8yrlT+XM3tUtFd34hCkWDX4hCkdm/BJpM/d/97nfJca+99lrdPnXqVLLv\n5MmTja9riviLpv0ll1xSty+++OJk34UXXli3L7jggrp97rnnJscNo9kbP3+TZ4Sl00KvY1j6sGck\nelDYS5KLqFxNlPEphRBnoMEvRKFo8AtRKNL8GaILqUnnv/LKK8lxJ06cqNuHDh1K9vEcwPz8fLIv\nRvyd5rLLLku2Wddv2rQp2bdu3bq6vWHDhrod5wZ4DmCQ+v+dd96p26+//nqyj7eb2kDzdQPSz8lz\nJ2vXrk2OO//88+s2u0uBM6MoVwu68wtRKBr8QhSKzP4M0YXEEXlsvr/88svJcQcOHKjbL730UrKP\nZcDc3Fyyr8l8Xb9+fbI9NjZWt3/7298m+6666qq6zS6raLrm3F69hM18IL2OUT4dP368bvM1Zndp\nPGd007F5f+mll9btKKVYLrErNZ5jNUkA3fmFKBQNfiEKRYNfiEKR5g+wey/qU3bvse7cv39/ctye\nPXvq9u7du5N9+/btW/AcQOrC4rDU6JZi914MH44hwwudD0jdWVEndzu8la/jq6++muz7zW9+U7cP\nH06XeuRtbse5AZ6LiZqc9fvll19et6+44orkuImJiQX7C6TzA/G7GOU5gEW/ZTP7lpnNm9kuem69\nme0wsz3V47rcOYQQw0ebf/HfBnBreO4eADvdfQuAndW2EGKEWNTsd/f/MbPJ8PRtALZW7fsBPALg\n7i72ayiI5h8X5jh69GjdZpcUAMzMzNTtaPaz+RpNds5WY3MyRpzx62IhEXbbcUQbR7ABaZRgPH83\nzH52k3KWI5v5QCqRXnzxxWQfX7vZ2dm6Ha83X7fYd3bvvf/976/bH/jAB5LjWDrEiEe+ptHM52s8\njJmSOZb7LY+5++lvYw7AWO5gIcTwseJ/8d6ZIWuso2Rm28xs2sym+W4phBgsy53tP2Jm4+4+a2bj\nAOabDnT37QC2A8DU1FRzsbUhgc3VaFJzNB3POHNEH5DO/h87dizZx6/LJaiw+Rpr/bEciclHPKvP\n5nwuoo0lANCdiD++dmymsyQCgGeeeaZuP/fcc8m+vXv31m1OgmIZAaTfWTS9We5wRGXuHLHwCZ8j\nzvbz9e5npGQ3WO6d/yEAd1TtOwA82J3uCCH6RRtX3/cA/BLAB83skJndCeA+ALeY2R4An6q2hRAj\nRJvZ/i807Lq5y30RQvSR0RIpfSBXH561NkfSxcw63o4Rbazfoyux6b1jdiHvizqTXYms6zm6LW7H\n+QB2X7V1+8U+8ufmORHW+ADw1FNP1e0XXngh2cduQdbo8brl4NfxdxbnBvgz83UD0qxKdh0CaZHU\nUjS/EGLE0eAXolBGy07pM7G4BruvONovRurlIvByNeaZ3BJUbPZGycEuMZYAXAAESBNb4r6LLrqo\nbke3F8OfJbot+b137arTQvD0008nx7E7Lyb2NJn6uWsYzfmmSMNYP/HgwYN1myMBgTTpJ7oIWQYM\nS13EtujOL0ShaPALUSga/EIUijR/ILdmW9O+3Lpvcd4gp+WbiK9pG4LcpP+BVONu3Lgx2cean11Z\nUWuzzo/FSJ944om6ze48zuID0my9OH+RC2NuInccfxdRu3OB0FiQld2WuXUC+b2l+YUQQ4sGvxCF\nIrM/QyzcwOY8Z3NFE49fF8/RbXMwmuLsgmTzNRbR4Oy6WKeezVd2ZUWJweeP2Xps9nO2XuwHm9Td\nkEg5+FrFKEGWMFF+8L5cVOaooTu/EIWiwS9EocjsDzSZ9kBa1IHbuWSPGCHXjfp4uaQfNs3ZpI6z\n/VzoI56DZ+BZEkSznCszRbOfZ/U5sYdXMI79bRv92A3ie/Fni58ztwowy7hRmOFndOcXolA0+IUo\nFA1+IQpFmj9DjNzj4o2shVnjA8DFF19ct7lIRDxndJ0xy3UhsT5tcvsB6dxDzMhjjR7nPZimJbSB\nNOIvFyE3KFdZnHvJLVnO32Hcx6+T5hdCjAQa/EIUisz+DNHE4/r27N6LiTEbNmyo2zF6jl1dsR5/\nzqXUlqZVhmPUGru64r64tFcTXLSEJQaQ1svLufMGZfZHE53lTfz8LPdi3f5Rq9vH6M4vRKFo8AtR\nKBr8QhTK6AqWPhDdQezy4VrusQAmzwGw/gfStfuiTm4qDJEjHsdals+XK0IRXX0xBHeh18TtmO3G\n8xfDkvnG32cMu+b5nDhPk3PrxqzNUaLNcl2bzexhM3vOzJ41s7uq59eb2Q4z21M9rlvsXEKI4aGN\n2f8OgK+4+7UAbgTwJTO7FsA9AHa6+xYAO6ttIcSI0GatvlkAs1X7lJk9D+AKALcB2Foddj+ARwDc\n3ZNeDglsKnKdu1xN/JhNx5Fvsd5/U826pZjNTXXkctl/ueWvcudoet+2/esH3H82+2PkJUdlxrr9\nvLRZUWY/Y2aTAK4H8CiAseofAwDMARhreJkQYghpPfjN7EIAPwTwZXdPVp/0zr/zBf+lm9k2M5s2\ns2nO/xZCDJZWg9/MzkFn4H/X3X9UPX3EzMar/eMA5hd6rbtvd/cpd5+KkXBCiMGxqOa3jmj6JoDn\n3f3rtOshAHcAuK96fLAnPRwiWN+x5o9LXG/atGnBNpBq/pMnTyb72B2XC/Xttr4eVr3eDVjzcygu\nu/aAdN5mfHw82cfuWq6ANOq08fN/DMCfAnjGzJ6snvsbdAb9A2Z2J4D9AG7vTReFEL2gzWz//wJo\nSlS+ubvdEUL0C0X4LRPOAosFPNlsvPLKK5N9bPZztB+QZsKx2Z8r+rFcRtGEb0PM1mty70WpNjk5\nWbc3b96c7Fu37r34tVHO4osotl+IQtHgF6JQVo8N02d45p+jw4A0Qiya/bxy7iuvvJLs45VjeeY/\nV2N+tZrv3YLlGSfoTExMJMfx9xQj/DiqrxvrLgwLq+eTCCGWhAa/EIWiwS9EoUjzd4FYGIJdQzHC\n7+qrr67bUfNzEQ0u9BGj/XKRgKXPAcQsOy7GyeHlcS6G5wCiGzC3dsEoozu/EIWiwS9Eocjs7wLR\n/cOuoVjog5N5eBkrIK2fz2Z/LLbB8iCa+U1FQJYiBzhKrqk4yFLotRTh6x8j8DgBiyVYjOLjAiwx\n6WeUC3bk0J1fiELR4BeiUDT4hSgUaf4ewK4hdvsBqUsp1svnrD525+Uy1doWBFmu7ub3jv3InbNp\nrqAb+j93PWKBTS7EwTr/qquuSo5j914s7rla0Z1fiELR4BeiUGT29wA2S6MJyWZoXKK7qWhHNHO5\njtzs7Gyyj92HfP7oLuRMwZwLL3dc0zoDQHeWG2dy8qNtbT6WXLGY7GrN3MtRxqcUQpyBBr8QhSKz\nv8fE6LDcMl9sYrMpG8tF8wrBMQmFF0ZhCRBXBGazPLf6LnsPoixhWRElDNPtCL9olnPyTlwVmSP3\nuLYiX0MAWLt2beP5VytlfEohxBlo8AtRKBr8QhSKNH+faSooCTRnp7EeBdJ1AmKxSdb8XCyEi4MC\nqZsuzgdwpCHPG8TiI01zA0Cz+7AbkYYxc4+vT5wD4eW12b0Xi65yQZblZi+OGove+c3sPDP7lZk9\nZWbPmtnXqufXm9kOM9tTPa5b7FxCiOGhjdn/JoCb3P3DAK4DcKuZ3QjgHgA73X0LgJ3VthBiRGiz\nVp8DOF1l4pzqzwHcBmBr9fz9AB4BcHfXe7iKiS48NjfZRRiTVThZiF1ZQFrog5N+otnPSUWxqAiv\nLXDw4MG6HeVBfB2z3EIiDF8PlkTxuvH1YDMfSGURuwHZ5QqsrmW42tJqws/M1lQr9M4D2OHujwIY\nc/fTsaVzAMYaTyCEGDpaDX53f9fdrwMwAeAGM/tQ2O/oWANnYGbbzGzazKZ5MkoIMViW5Opz9xMA\nHgZwK4AjZjYOANXjfMNrtrv7lLtPxWQKIcTgWFTomNlGAG+7+wkzWwvgFgD/COAhAHcAuK96fLCX\nHR0GmrRrfD7nKsrtY3cTa9y4LgDPAcQwVXbTsa6P4bdcLDRmBvJ8w8svv9zYX3YXxhDhbtCk+WOm\nJLtMo6uPbzjsIo3nKMW9x7SZ5RgHcL+ZrUHHUnjA3X9iZr8E8ICZ3QlgP4Dbe9hPIUSXaTPb/zSA\n6xd4/jiAm3vRKSFE7ynPvxHI1b1vuzR2LFyRywpjkzoex9t8XIzwYxkQi1c01fCLZj+7AeM+7kcu\nc6/bS4VH05u3OTIyuunYhceZe0BzVF+UUiWa/YrtF6JQNPiFKJQizX42V6PJzlFs0cxtWjk3niNX\nb47NzVjog2eg2cyNEW25mW8+lk3xmHjDnoBY348/J3sPuB1f14sluZo+Z0zK4Rn+GOHHkoAlUikF\nO3LoCghRKBr8QhSKBr8QhbJqNX/UoKxPWe9GHcsFK06dOpXsa3KPxWw3Jmp+LjYZtTxrWXZnRXce\nnyNqfp4r4PeO8xKckRdzLo4cOVK3OcJvKa6+tnMAufkRnhPhzxmjGjlzLxZF5Yw/vt4luvYiuvML\nUSga/EIUyqoy+3OuLU5kOX78eN0+duxYchwnufBx8Vg+XzT7OTIwupTYhI8mOyeesLkaa9FzIks0\ngVkucGRglDAsb6LZzwVBWBZFs58/Zy8i/Ngtyp8rl7wT98m914yuhhCFosEvRKFo8AtRKCOt+aPO\n5LXk2C0HpHqdi1Lu378/OW7fvn11O2rhubm5us06PxbHZBdV7CMX4sitwZdb049DWGPdfj6WXYc8\nRwEAhw8frtuxmAcX8GSXYAwDZqJeX84cQNTkTWsc5DQ/z5UAzQVShO78QhSLBr8QhTJyZn+uiAab\nttFkf+mll+r27t276/aePXsaj2PzF0jdY2z2x6Wrc+Ylm6GxVjyb6RzFFwufstkb6/Zv2rSpbrMJ\nHPvIn5PlDNAcyRiLmyynNn+uYEe8HuymYzdodH3y9YlrHMSiHeI9dOcXolA0+IUolJE2+2NkHUem\nHTp0KNm3d+/eur1r1666Hc1+9gTEqDh+v9zMN/cxmrksCaI8YFnBngBOtAHSme84U8+eAPYeRJOd\nZVG8VpzMw5GSvS7PzbP7QCp9+LNEGcSSgF8Tzy9SdOcXolA0+IUoFA1+IQpl5DQ/a+0YWcdRfAcO\nHEj2sXuP9f/MzExyHOvumBkYXYsrJepRfr+mIppAGnUXl9PiOQB2lUU3Gp8zZi82zW0st2BHjtz6\nBOyqZJ0fi3TmluGKRVLFe7S+81fLdD9hZj+ptteb2Q4z21M9rlvsHEKI4WEpZv9dAJ6n7XsA7HT3\nLQB2VttCiBGhldlvZhMA/gTAPwD4q+rp2wBsrdr3A3gEwN3d7V6Hpqi+6IrjiDx22QGpDOCkFnYP\nAu0j2rpBbnVffu8oN1gecD1CII1y5Oi26EbjiL94jtw1WCm5On3R7GdzPpe8w/Imfk7RTNs7/zcA\nfBUA/xLG3P20wJwDMHbGq4QQQ8uig9/MPgtg3t0fbzrGO7ewBW+LZrbNzKbNbDrG2wshBkebO//H\nAHzOzGYAfB/ATWb2HQBHzGwcAKrH+YVe7O7b3X3K3adiZJYQYnAsqvnd/V4A9wKAmW0F8Nfu/kUz\n+ycAdwC4r3p8sFedZG3MejRqfrYsYqYah8hy1lp053W7KOVSaPt+PAcQNTm75lhP58Jcc+dYTuZe\nhN87hjSza47DloHmevwxq481v1x77VlJkM99AG4xsz0APlVtCyFGhCUF+bj7I+jM6sPdjwO4uftd\nEkL0g5GI8GNzk11UsS4dR+fFyDd26bF0iG60fpv6bVhKn5qWDs+Z/b3+zLmCHezei2sQcNESni+K\n8kDLcC0PxfYLUSga/EIUykiY/TwbzbPzMeGFZUCUBGzq55JVRo1e978bM/zcjuXKOYovliHneoRs\n9nOtQ0BRfctFd34hCkWDX4hC0eAXolBGQvMz7L6K0Xms63OFOPrp2loKvexXv+c2mtx7UfOzOy8W\n6eA1CTiqL9bml3tveejOL0ShaPALUSgjYfY3mazx+VzCSy9qzp8mZ3YuxSTlY3Nm+jC6J3PLcHGy\nTayrz66+uBoxm/p8XFyCS2b/8tCdX4hC0eAXolA0+IUolJHQ/EyuMETTcZFuaOa2Oj/2sa0+7adr\ncrm0vcas+aNe530x44+3OYR3WK/HqKE7vxCFosEvRKGMhNnPpnPOTGTTMGdC5uRCW9j0XIr84H7E\nfU318nJuykGawLmlyJuOi8VTcjUZuSALr8kQP3Oubn83vuvViq6MEIWiwS9EoYyE2d8ULRaTRDh6\nLO5jc5BNwW54BeJxfP7cyraxzDSb93yOXkYn9oO2KyvHFZM5gYfPwQk/QJoQxJGA8Rx8veO1LzFK\nUHd+IQpFg1+IQtHgF6JQRkLzM6zdY1GHiy66aME2kC4LlVvGqhv6ms+R0/XR7cWMWhRbbrlx1uux\nsCovoxa/C3YD8tzA5ORkctzExETdjpmBPB/Av4n42+HfVfzOVqu7sNXgrxbpPAXgXQDvuPuUma0H\n8J8AJgHMALjd3V9pOocQYrhYyr+0T7r7de4+VW3fA2Cnu28BsLPaFkKMCCsx+28DsLVq34/OGn53\nr7A/C9JUD45NeSBdxim6fDgKjJNL3njjjcb3Wq6rj88RTfvcKsDLWRE3FyU4SJoiFNmUB4Djx4/X\nbV6KDUglApv9s7OzyXFXXnll3WYJAKRuQV4XIC4Xz7+dWHCEfy+raRXgtnd+B/ALM3vczLZVz425\n++lvYQ7A2MIvFUIMI23v/B9398NmdjmAHWb2a97p7m5mC95yqn8W24D0P7QQYrC0uvO7++HqcR7A\njwHcAOCImY0DQPU43/Da7e4+5e5T0dQSQgyORe/8ZnYBgLPc/VTV/jSAvwfwEIA7ANxXPT7Yq06y\nq4VdMqzjgbQGfG65Z3YvxfX+cpq8LblsN97HLrB47HLnG4aFpn7lsvp4iXUg/W44LPjo0aPJcbwd\n5wN43+bNm+t2tEJ5biD+dthFGMPGR3kOoI3ZPwbgx9UP82wA/+HuPzOzxwA8YGZ3AtgP4PbedVMI\n0W0WHfzuvg/Ahxd4/jiAm3vRKSFE7xm5CD929cUoLTbXxsfHk30838BuwFhAIrd893JM7G6Y5cNq\n2rcl58LMFS3h74KXX3v11VeT4/g7ZNchAJw4caJus6yILl4+f5Qm3Me4PDjLgFGTAKszblEIsSga\n/EIUiga/EIUy0po/hmGuW7eubkfNz24edv9Ezc/aL4aidsMNmKOX2n4pFYuaju33Z25aezG6SPk7\ni65bdhFyuHAuozK68zi8NxYIZZ3ftkLUsKA7vxCFosEvRKGMnNnP5lTM6mM3zKZNm5J9bOpzhlh0\nG7Gpz24iIDUvey0BlkuTuZkzQ3PFKvoZadj2HNHsz0kCzhTMmfps2kc5ydtr165N9rFEYEk6Cm4/\n3fmFKBQNfiEKZeTMfiaaVmz2c+02IK37xjPAr7/+enIcm4nRDD158uSCx8XItOUU5Vgu0ZxvWiE4\nXqvcsmdNy2vFYhv8uXu9pFjuHPzesY/8XfO1iasFc3QoF/0AUs9R/L1wctmoRfvpzi9EoWjwC1Eo\nGvxCFMpIa/7oomLXXyzIwBF+nNEVs7tY4+aW12b9HyMB+RxLyQxsu+R1k66PfcxlQPJ2bllrvj5x\nnT2OpmM3KHCmy+00/Y4S5H7wZ4nrB3DGHy8NDqTu4Ph74fPn3L/DGPGnO78QhaLBL0ShjLTZH2H3\nSqzvx66/poSReI7oAuNIr8OHD9dtlgBAag7HqLK2kiBn2nMfo8nOfWTpw0lPQFrTMEoCfm/+bNEc\n5qjJWH+PJQKbxr1eoqxtolB0CXIfcxGEwxTNuVJ05xeiUDT4hSgUDX4hCmVVaX4mamFeiy0Hh33G\nrMEmDc3rAABpEclYXILdgnG+gbdzoai8HZci5z5yLfpY3IS34/wI61rW/IcOHUqOO3DgQOO+poIp\nOddq2xDhpbjN+NjcXAnP7+RCplcTuvMLUSga/EIUyqo1+yNsKnPd/mjS5Yo6sKm/YcOGuj03N5cc\nNz//3rKF0Q3IkWW5LDk2Q6PZz2Z6jGTk9QnYtI/LU42NvbeocjwH94NdeCwjgPQaRFfiwYMH6zZf\nn9ySXDn323KXLG+q+Rjr73P/2Q0KNC/vHs+fK4oyjLTqrZldamY/MLNfm9nzZvZRM1tvZjvMbE/1\nuG7xMwkhhoW2/6r+GcDP3P0P0Fm663kA9wDY6e5bAOystoUQI0KbVXovAfAJAH8GAO7+FoC3zOw2\nAFurw+4H8AiAu3vRyW7DM70sAYDUrIuRb3wsF3xgMx9IawTmzP6YEMRmLpuTsW4cz/BHc5vNfo5q\njMujs2kbPQYMJ7XEa8UelNgPfu+ZmZm6HT0j7BWIyTZcOKMpgQZontEH0mvHfYw1HlnSxEIwLBGi\nFGzyEoyCh6DNnf9qAEcB/LuZPWFm/1Yt1T3m7qfXQ55DZzVfIcSI0Gbwnw3gjwD8q7tfD+A1BBPf\nO7MxC87ImNk2M5s2s+m4rroQYnC0GfyHABxy90er7R+g88/giJmNA0D1OL/Qi919u7tPuftUND2F\nEINjUc3v7nNmdtDMPujuuwHcDOC56u8OAPdVjw/2tKc9Imbu5dw6PAfAmjlGz7FOjsuBsa6N2WMc\n7cb9ipGGOZcVb7MmzxXziNeAybk++fzRXci6mducDQkAs7OzdTu6AZuW1I4uQdbXuchOdk1ec801\nyXFbtmyp29Glyd91vAb8fqPm6mvr5/9LAN81s3MB7APw5+hYDQ+Y2Z0A9gO4vTddFEL0glaD392f\nBDC1wK6bu9sdIUS/KCbCry1susXVWpuixWLSEJuosbYdu/diYQt2YeWSUNgUj9KEXVu8L5r2bevK\n8znia3KSgN2CbPZzLUUgNfvjhDAXD+FIwOgizSVB8XfDc07RtOftWLefpVR0u+YSgoad0RIpQoiu\nocEvRKFo8AtRKNL8GXIZYqx/cy7BnK7PFa9oW8Az7uPtbruecqGzbTMPo56emJio27FAKC+RzgVB\no+bnjL+c67YpKzNuxzDmpvX4gPSaSPMLIUYCDX4hCsX6WYfczI6iExC0AcCxRQ7vB+pHivqRMgz9\nWGofrnL3VnH0fR389ZuaTbv7QkFD6of6oX70qQ8y+4UoFA1+IQplUIN/+4DeN6J+pKgfKcPQj571\nYSCaXwgxeGT2C1EofR38Znarme02s71m1rdqv2b2LTObN7Nd9FzfS4+b2WYze9jMnjOzZ83srkH0\nxczOM7NfmdlTVT++Noh+UH/WVPUhfzKofpjZjJk9Y2ZPmtn0APvRtzL5fRv8ZrYGwL8A+GMA1wL4\ngpld26e3/zaAW8Nzgyg9/g6Ar7j7tQBuBPCl6hr0uy9vArjJ3T8M4DoAt5rZjQPox2nuQqcc/GkG\n1Y9Puvt15FobRD/6Vybf3fvyB+CjAH5O2/cCuLeP7z8JYBdt7wYwXrXHAezuV1+oDw8CuGWQfQFw\nPoD/A/CRQfQDwET1g74JwE8G9d0AmAGwITzX134AuATAS6jm4nrdj36a/VcAOEjbh6rnBsVAS4+b\n2SSA6wE8Ooi+VKb2k+gUXt3hnQKtg7gm3wDwVQCc5TSIfjiAX5jZ42a2bUD96GuZfE34IV96vBeY\n2YUAfgjgy+7+Ku/rV1/c/V13vw6dO+8NZvahfvfDzD4LYN7dH8/0s1/fzcer6/HH6MixTwygHysq\nk79U+jn4DwPgGk4T1XODolXp8W5jZuegM/C/6+4/GmRfAMDdTwB4GJ05kX7342MAPmdmMwC+D+Am\nM/vOAPoBdz9cPc4D+DGAGwbQjxWVyV8q/Rz8jwHYYmZXV1WAPw/goT6+f+QhdEqOA30qPW6dhO9v\nAnje3b8+qL6Y2UYzu7Rqr0Vn3uHX/e6Hu9/r7hPuPonO7+G/3f2L/e6HmV1gZhedbgP4NIBd/e6H\nu88BOGhmH6yeOl0mvzf96PVESpi4+AyAFwC8COBv+/i+3wMwC+BtdP673gngMnQmmvYA+AWA9X3o\nx8fRMdmeBvBk9feZfvcFwB8CeKLqxy4Af1c93/drQn3aivcm/Pp9Pa4B8FT19+zp3+aAfiPXAZiu\nvpv/ArCuV/1QhJ8QhaIJPyEKRYNfiELR4BeiUDT4hSgUDX4hCkWDX4hC0eAXolA0+IUolP8H7uon\nuqeydG8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd60957898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output label: 2, score: 99.73%\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.dataset import imread, imshow, imshow_array, imresize, normalize_array, im2bw, pil2array, rgb2gray\n",
    "\n",
    "image = imread('/home/ashok/Projects/ml-for-all-github/data/five.png')\n",
    "\n",
    "imshow(image)\n",
    "\n",
    "if image.size != image_size:\n",
    "    image = imresize(image, image_size)\n",
    "    \n",
    "image = rgb2gray(image)\n",
    "image  = pil2array(image)\n",
    "image = normalize_array(image)\n",
    "image = np.reshape(image, (image_size[0]*image_size[1]*image_channel))\n",
    "image  = np.reshape(np.asarray(image), image_size[0]*image_size[1]*image_channel)\n",
    "\n",
    "output  = sess.run(pred_probas, feed_dict={x:[image]})\n",
    "output_label = np.argmax(output)\n",
    "\n",
    "print('Output label: {}, score: {:.2f}%'.format(output_label, output[0][output_label]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
